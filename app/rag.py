# app/rag.py
import httpx
from typing import List, Dict, Any, Tuple
from qdrant_client import QdrantClient
from fastembed import TextEmbedding
from app.settings import get_settings

S = get_settings()

# ---------------- Embeddings (FastEmbed) ----------------
# Modelo multiling√ºe (espa√±ol OK), 384 dims
_EMBED_MODEL_NAME = "intfloat/multilingual-e5-small"
_EMBEDDER = TextEmbedding(model_name=_EMBED_MODEL_NAME)

def _connect_qdrant() -> QdrantClient:
    return QdrantClient(url=S.URL_QDRANT, api_key=S.CLAVE_API_QDRANT, timeout=60)

def embed_text(texts: List[str]) -> List[List[float]]:
    # FastEmbed devuelve un generador ‚Üí lo convertimos a listas
    return [vec for vec in _EMBEDDER.embed(texts)]

def retrieve(query: str, k: int = 4) -> List[Dict[str, Any]]:
    client = _connect_qdrant()
    qvec = embed_text([query])[0]
    res = client.search(
        collection_name=S.COLECCION_QDRANT,
        query_vector=qvec,
        limit=k,
        with_payload=True
    )
    out = []
    for p in res:
        payload = p.payload or {}
        out.append({"text": payload.get("text", ""), "page": payload.get("page"), "score": float(p.score)})
    return out

def build_prompt(user_msg: str, ctx_snippets: List[Dict[str, Any]]) -> str:
    ctx_txt = "\n\n".join([f"- (p√°g.{c.get('page','?')}) {c['text']}" for c in ctx_snippets])
    system = (
        "Eres el asistente virtual OFICIAL de la C√°mara de Comercio de Pamplona (Colombia). "
        "Responde con informaci√≥n precisa y breve, en espa√±ol, usando S√ìLO el contexto provisto. "
        "Si el usuario pregunta algo general (saludos, despedidas, cortes√≠as), responde de forma cordial y breve. "
        "Si el usuario pide informaci√≥n fuera del √°mbito de la C√°mara, responde: "
        "\"Lo siento, solo puedo ayudarte con informaci√≥n de la C√°mara de Comercio de Pamplona.\" "
        "Cuando el tema sea de la C√°mara, usa listas cortas y evita inventar datos."
    )
    final = (
        f"{system}\n\n"
        f"Contexto autorizado (extractos):\n{ctx_txt if ctx_txt else '- (sin coincidencias relevantes)'}\n\n"
        f"Instrucciones:\n"
        f"- M√°ximo 6 l√≠neas por respuesta.\n"
        f"- Si no encuentras respuesta en el contexto, dilo de forma clara.\n"
        f"- Incluye tel√©fonos/horarios solo si est√°n en el contexto.\n"
        f"- No repitas el contexto.\n"
        f"Usuario: {user_msg}\n"
        f"Respuesta:"
    )
    return final

def is_greeting_or_farewell(text: str) -> Tuple[bool, str]:
    t = (text or "").lower()
    saludos = ["hola", "buenos d√≠as", "buenas tardes", "buenas noches", "qu√© tal", "buen d√≠a"]
    desped = ["gracias", "muchas gracias", "hasta luego", "chao", "adi√≥s", "nos vemos"]
    if any(s in t for s in saludos):
        return True, ("¬°Hola! üëã Soy el asistente de la C√°mara de Comercio de Pamplona. "
                      "¬øEn qu√© puedo ayudarte? Puedo orientarte sobre matr√≠cula, renovaci√≥n, "
                      "ESAL, conciliaci√≥n, RUES, certificados y eventos.")
    if any(d in t for d in desped):
        return True, ("¬°Con gusto! üòä Si necesitas algo m√°s de la C√°mara de Comercio de Pamplona, "
                      "escr√≠beme cuando quieras. ¬°Que tengas un excelente d√≠a!")
    return False, ""

async def call_groq_chat(system_prompt: str) -> str:
    url = "https://api.groq.com/openai/v1/chat/completions"
    headers = {"Authorization": f"Bearer {S.CLAVE_GROQ}", "Content-Type": "application/json"}
    payload = {
        "model": S.MODELO_GROQ,
        "messages": [
            {"role": "system", "content": "Sigue las instrucciones y responde solo en espa√±ol."},
            {"role": "user", "content": system_prompt},
        ],
        "temperature": 0.2,
        "max_tokens": 350,
    }
    async with httpx.AsyncClient(timeout=S.TIMEOUT_HTTP) as client:
        r = await client.post(url, headers=headers, json=payload)
        data = r.json()
        try:
            return data["choices"][0]["message"]["content"].strip()
        except Exception:
            return f"No pude generar respuesta (Groq). Detalle: {data}"

async def answer_with_rag(user_msg: str) -> str:
    ok_small, smalltalk = is_greeting_or_farewell(user_msg)
    if ok_small:
        return smalltalk
    ctx = retrieve(user_msg, k=5)
    prompt = build_prompt(user_msg, ctx)
    answer = await call_groq_chat(prompt)
    if not ctx:
        answer += "\n\n(No encontr√© coincidencias en los documentos; intenta con otra consulta o actualiza el PDF)."
    return answer
